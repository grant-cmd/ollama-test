name: Ollama MCP Server with Ngrok (Fixed Port Conflict)

on:
  workflow_dispatch:

jobs:
  setup-ollama-with-ngrok:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y curl wget jq lsof

    - name: Check for processes using port 11434
      run: |
        echo "Checking for processes using port 11434..."
        if lsof -i :11434 >/dev/null 2>&1; then
          echo "Processes using port 11434:"
          lsof -i :11434
          echo "Killing processes using port 11434..."
          sudo kill -9 $(lsof -t -i :11434) 2>/dev/null || true
          sleep 2
        else
          echo "No processes found using port 11434"
        fi

    - name: Install Ollama
      run: |
        curl -fsSL https://ollama.com/install.sh | sh
        echo "Ollama installed successfully"

    - name: Create Ollama directory structure
      run: |
        mkdir -p ~/.ollama/logs
        echo "Ollama directory structure created"

    - name: Start Ollama with MCP enabled on alternative port
      env:
        OLLAMA_MCP_ENABLE: "true"
        OLLAMA_HOST: "0.0.0.0:11435"  # Use alternative port
      run: |
        # Start Ollama on alternative port
        ollama serve > ~/.ollama/logs/server.log 2>&1 &
        OLLAMA_PID=$!
        echo "Ollama started with PID: $OLLAMA_PID on port 11435"
        
        # Wait for server to start
        sleep 10
        
        # Verify Ollama is running
        if curl -s http://localhost:11435/api/tags >/dev/null; then
          echo "‚úÖ Ollama server is running on port 11435"
          echo "Ollama logs:"
          cat ~/.ollama/logs/server.log
        else
          echo "‚ùå Ollama server failed to start"
          cat ~/.ollama/logs/server.log
          exit 1
        fi

    - name: Pull model
      env:
        OLLAMA_MCP_ENABLE: "true"
        OLLAMA_HOST: "0.0.0.0:11435"
      run: |
        ollama pull deepseek-r1:1.5b
        echo "Model pulled successfully"

    - name: Install ngrok
      run: |
        wget -q https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz
        tar -xzf ngrok-v3-stable-linux-amd64.tgz
        sudo mv ngrok /usr/local/bin/
        ngrok --version

    - name: Setup ngrok authentication
      run: |
        ngrok config add-authtoken ${{ secrets.NGROK_AUTH_TOKEN }}
        echo "Ngrok authtoken configured"

    - name: Start ngrok tunnel to alternative port
      run: |
        # Start ngrok tunnel to alternative port 11435
        ngrok http 11435 --log=stdout > ngrok.log 2>&1 &
        echo "Ngrok started with PID: $!"
        sleep 10
        
        # Get ngrok public URL
        NGROK_URL=$(curl -s http://localhost:4040/api/tunnels | jq -r '.tunnels[0].public_url')
        echo "Ngrok Public URL: $NGROK_URL"
        echo "NGROK_URL=$NGROK_URL" >> $GITHUB_ENV
        
        # Test basic connection
        if curl -s "$NGROK_URL/api/tags" >/dev/null; then
          echo "‚úÖ Ngrok tunnel is working correctly"
        else
          echo "‚ùå Ngrok tunnel test failed"
          echo "Ngrok logs:"
          cat ngrok.log
          exit 1
        fi

    - name: Test Ollama through ngrok
      run: |
        echo "Testing Ollama API through ngrok..."
        
        # Test with correct endpoint
        response=$(curl -s -w "\n%{http_code}" \
          -X POST "$NGROK_URL/api/generate" \
          -H "Content-Type: application/json" \
          -d '{"model": "deepseek-r1:1.5b", "prompt": "Hello", "stream": false}')
        
        http_code=$(echo "$response" | tail -n1)
        response_body=$(echo "$response" | sed '$d')
        
        echo "HTTP Response Code: $http_code"
        echo "Response Body: $response_body"
        
        if [ "$http_code" -eq 200 ]; then
          echo "‚úÖ Ollama API test successful"
        else
          echo "‚ùå Ollama API test failed with HTTP $http_code"
          echo "Trying diagnostic request to /api/tags..."
          curl -v "$NGROK_URL/api/tags"
          exit 1
        fi

    - name: Show connection details
      run: |
        echo "=== CONNECTION DETAILS ==="
        echo "Public Ngrok URL: $NGROK_URL"
        echo "Local Ollama URL: http://localhost:11435"
        echo "MCP Enabled: true"
        echo "=========================="
        echo "Test with:"
        echo "curl -X POST $NGROK_URL/api/generate -H 'Content-Type: application/json' -d '{\"model\": \"deepseek-r1:1.5b\", \"prompt\": \"Hello\"}'"

    - name: Keep server running for testing
      run: |
        echo "üöÄ Server is running!"
        echo "‚è∞ Keeping server running for 10 minutes..."
        sleep 600
